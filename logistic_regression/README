README

Assume input x is scalar and there are 3 classes with equal priors. Each
conditional density is normal:
f(x | y = a) = N(2a, 1), a = 1, 2, 3.

1): Sample 100 points from each class and train a logistic regression based
	on this training data. Plot on the same graph the estimated posterior
	probability p(y = 1 | x) based on the logistic regression you trained
	and the posterior probability based on the true distribution:
	p(y = 1 | x) =
	f(x | y = 1)
	f(x | y = 1) + f(x | y = 2) + f(x | y = 3)
2): Draw the graph for x in the range [0, 10]

Notes:
(a) In this exercise we were not allowed to use any machine learning packages or tools
	(e.g. scikit-learn, PyBrain, PyML, etc.).
(b) I used numpy package
(c) In this exercise we were restricted to Python 2.7 only.

In this exercise are two files attached:
1): ex2.py - the code file.
2): myplot.png - the graph output.
